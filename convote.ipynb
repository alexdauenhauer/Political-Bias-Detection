{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/alex/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/alex/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package names to /home/alex/nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n",
      "[nltk_data] Downloading package opinion_lexicon to\n",
      "[nltk_data]     /home/alex/nltk_data...\n",
      "[nltk_data]   Package opinion_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import time, os, pickle\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords, names, opinion_lexicon\n",
    "from collections import Counter\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('names')\n",
    "nltk.download('opinion_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = r'/home/alex/Documents/MIDS/w266/final_project/data/convote_v1.1/data_stage_three'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_set', 'development_set', 'training_set']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(datapath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "combine the three datasets into one since we are adding it to other datasets later and will do a train test split on the full data at that point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_set : 860\n",
      "development_set : 257\n",
      "training_set : 2740\n",
      "Total files : 3857\n"
     ]
    }
   ],
   "source": [
    "# check how many files we are working with and load them into a list\n",
    "files = []\n",
    "# party2label = {'D':'liberal','R':'conservative','I':'neutral'}\n",
    "party2label = {'D':1,'R':-1,'I':0}\n",
    "\n",
    "# iterate through directory\n",
    "for i, (dirName, subDirList, fileList) in enumerate(os.walk(datapath)):\n",
    "    if i > 0:\n",
    "        # print the number of files in each dataset\n",
    "        print(os.listdir(datapath)[i-1], ':', len(fileList))\n",
    "    for i,f in enumerate(fileList):\n",
    "        # convert from party label to ideological label\n",
    "        label = party2label[f.split('_')[-1][0]]\n",
    "        \n",
    "        # store the filepath with the label attached\n",
    "        filepath = os.path.join(dirName,f)\n",
    "        files.append((label, filepath))\n",
    "print('Total files :', len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences:  54830\n"
     ]
    }
   ],
   "source": [
    "# parse sentences and load into a DataFrame\n",
    "sentences = []\n",
    "for label, filename in files:\n",
    "    with open(filename, 'r') as f:\n",
    "        # split the sentences\n",
    "        sents = sent_tokenize(f.read())\n",
    "        \n",
    "        # collect (label, sentence) tuples\n",
    "        for sent in sents:\n",
    "            sentences.append((label, sent))\n",
    "\n",
    "df = pd.DataFrame(sentences, columns=['label', 'text'])\n",
    "print('Total sentences: ', df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29305</th>\n",
       "      <td>1</td>\n",
       "      <td>when congress passed h. con .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50317</th>\n",
       "      <td>1</td>\n",
       "      <td>the one aspect of this bill that seems directe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38126</th>\n",
       "      <td>-1</td>\n",
       "      <td>the states , the courts and the american peopl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54484</th>\n",
       "      <td>1</td>\n",
       "      <td>mr. speaker , the gentleman brags about the ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22354</th>\n",
       "      <td>-1</td>\n",
       "      <td>mr. speaker , i thank the gentleman for yieldi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text\n",
       "29305      1                      when congress passed h. con .\n",
       "50317      1  the one aspect of this bill that seems directe...\n",
       "38126     -1  the states , the courts and the american peopl...\n",
       "54484      1  mr. speaker , the gentleman brags about the ad...\n",
       "22354     -1  mr. speaker , i thank the gentleman for yieldi..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>26155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text\n",
       "label       \n",
       "-1     26155\n",
       " 0       236\n",
       " 1     28439"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine most politically charged bigrams and trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into liberal and conservative\n",
    "lib = df.loc[df.label == 1]\n",
    "con = df.loc[df.label == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops = [w.lower() for w in stopwords.words('english')] + \\\n",
    "        ['``', \"'s\", 'sensenbrenner', 'chairman', \"n't\", 'support','extraneous','even', 'thank']\n",
    "#         ['would', 'could','really','sensenbrenner',\"n't\"]\n",
    "        \n",
    "stops[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "men = [w.lower() for w in names.words('male.txt')]\n",
    "women = [w.lower() for w in names.words('female.txt')]\n",
    "stopNames = men + women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops = opinion_lexicon.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188, 7944, 6789)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stops), len(stopNames), len(ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops.extend(stopNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = set(stops)\n",
    "ops = set(ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7761, 6786)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stops), len(ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a helper function to pull the bigrams\n",
    "def getNgrams(text, stops=None, ops=None, n=2):\n",
    "    '''return all bigrams in a Counter'''\n",
    "    def criteria(word):\n",
    "        if stops:\n",
    "            if len(word) > 1 and not word.isnumeric() and word not in stops:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "            return True\n",
    "            \n",
    "    # intialize counter\n",
    "    ngrams = Counter()\n",
    "    \n",
    "    # tokenize text\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # filter punctuation and single letter words\n",
    "    words = [w.lower() for w in words]\n",
    "    \n",
    "    # throw out sentences with less than two words\n",
    "    if len(words) < 2:\n",
    "        return ngrams\n",
    "    \n",
    "    # add bigrams to Counter\n",
    "    for i in range(len(words) - (n-1)):\n",
    "        gram = ' '.join(words[i:i+n])\n",
    "        if all([criteria(w) for w in words[i:i+n]]):\n",
    "            if ops:\n",
    "                if any([w in ops for w in words[i:i+n]]):\n",
    "                    ngrams[gram] += 1\n",
    "            else:\n",
    "                ngrams[gram] += 1\n",
    "        \n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28439/28439 [00:06<00:00, 4846.82it/s]\n"
     ]
    }
   ],
   "source": [
    "libTrigrams = Counter()\n",
    "for text in tqdm(lib.text):\n",
    "#     libBigrams.update(getBigrams(text, stops))\n",
    "    libTrigrams.update(getNgrams(text, stops=stops, n=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28439/28439 [00:06<00:00, 4709.07it/s]\n"
     ]
    }
   ],
   "source": [
    "libBigrams = Counter()\n",
    "for text in tqdm(lib.text):\n",
    "#     libBigrams.update(getBigrams(text, stops))\n",
    "    libBigrams.update(getNgrams(text, stops=stops, ops=ops, n=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26155/26155 [00:05<00:00, 4547.01it/s]\n"
     ]
    }
   ],
   "source": [
    "conTrigrams = Counter()\n",
    "for text in tqdm(con.text):\n",
    "    conTrigrams.update(getNgrams(text, stops=stops, n=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26155/26155 [00:05<00:00, 4634.27it/s]\n"
     ]
    }
   ],
   "source": [
    "conBigrams = Counter()\n",
    "for text in tqdm(con.text):\n",
    "    conBigrams.update(getNgrams(text, stops=stops, ops=ops, n=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "most of these bigrams are neutral. Grab the 1000 most common from each ideology, then filter out any that appear in the other ideology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the 1000 most common liberal and conservative bigrams\n",
    "commonConTrigrams = [b[0] for b in conTrigrams.most_common()[:1000]]\n",
    "commonLibTrigrams = [b[0] for b in libTrigrams.most_common()[:1000]]\n",
    "commonConBigrams = [b[0] for b in conBigrams.most_common()[:1000]]\n",
    "commonLibBigrams = [b[0] for b in libBigrams.most_common()[:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the bigrams for each ideology that appear in the top 1000 of that ideology and not in the top 1000 of the other\n",
    "libTrigrams_filtered = [(w, libTrigrams[w]) for w in commonLibTrigrams if w not in commonConTrigrams]\n",
    "libBigrams_filtered = [(w, libBigrams[w]) for w in commonLibBigrams if w not in commonConBigrams]\n",
    "# conservative bigrams also had weird 'amp nbsp' HTML tags so remove those\n",
    "conTrigrams_filtered = [(w, conTrigrams[w]) for w in commonConTrigrams if w not in commonLibTrigrams]\n",
    "conBigrams_filtered = [(w, conBigrams[w]) for w in commonConBigrams if w not in commonLibBigrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(751, 751, 665, 665)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(libTrigrams_filtered),len(conTrigrams_filtered),len(libBigrams_filtered),len(conBigrams_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 10 liberal trigrams:\n",
      "social security trust\n",
      "security trust fund\n",
      "cbc alternative budget\n",
      "black caucus budget\n",
      "estate tax relief\n",
      "privatize social security\n",
      "u.s. trade deficit\n",
      "republican budget resolution\n",
      "national wildlife refuge\n",
      "guardian ad litem\n"
     ]
    }
   ],
   "source": [
    "print('top 10 liberal trigrams:')\n",
    "# sorted(libTrigrams_filtered,key=lambda x: -x[1])[:10]\n",
    "for k,v in sorted(libTrigrams_filtered,key=lambda x: -x[1])[:10]:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 10 liberal bigrams:\n",
      "tax breaks\n",
      "security trust\n",
      "bad policy\n",
      "would lose\n",
      "reduce crime\n",
      "budget reconciliation\n",
      "ethical standard\n",
      "fiscally irresponsible\n",
      "working poor\n",
      "subpoena power\n"
     ]
    }
   ],
   "source": [
    "print('top 10 liberal bigrams:')\n",
    "for k,v in sorted(libBigrams_filtered,key=lambda x: -x[1])[:10]:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 10 conservative trigrams\n",
      "national electrical contractors\n",
      "electrical contractors association\n",
      "legislative days within\n",
      "inner cell mass\n",
      "head start program\n",
      "community protection act\n",
      "million new jobs\n",
      "death tax repeal\n",
      "9/11 commission report\n",
      "stem cells without\n"
     ]
    }
   ],
   "source": [
    "print('top 10 conservative trigrams')\n",
    "for k,v in sorted(conTrigrams_filtered,key=lambda x: -x[1])[:10]:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 10 conservative bigrams\n",
      "community protection\n",
      "free market\n",
      "organized crime\n",
      "bankruptcy relief\n",
      "good news\n",
      "relief extension\n",
      "delayed notification\n",
      "soft money\n",
      "illegal aliens\n",
      "invasive species\n"
     ]
    }
   ],
   "source": [
    "print('top 10 conservative bigrams')\n",
    "for k,v in sorted(conBigrams_filtered,key=lambda x: -x[1])[:10]:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep just the bigrams and drop the count data\n",
    "libGrams = [k for k,v in sorted(libTrigrams_filtered,key=lambda x: -x[1])[:100]] + \\\n",
    "           [k for k,v in sorted(libBigrams_filtered,key=lambda x: -x[1])[:100]]\n",
    "conGrams = [k for k,v in sorted(conTrigrams_filtered,key=lambda x: -x[1])[:100]] + \\\n",
    "           [k for k,v in sorted(conBigrams_filtered,key=lambda x: -x[1])[:100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# savepath = r'../data'\n",
    "# with open(os.path.join(savepath, 'libGrams.pickle'), 'wb') as f:\n",
    "#     pickle.dump(libGrams, f, pickle.HIGHEST_PROTOCOL)\n",
    "# with open(os.path.join(savepath, 'conGrams.pickle'), 'wb') as f:\n",
    "#     pickle.dump(conGrams, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open('../data/libGrams5.pickle', 'wb') as f:\n",
    "    pickle.dump(libGrams, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open('../data/conGrams5.pickle', 'wb') as f:\n",
    "    pickle.dump(conGrams, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['social security trust', 'security trust fund', 'cbc alternative budget', 'black caucus budget', 'estate tax relief']\n",
      "['national electrical contractors', 'electrical contractors association', 'legislative days within', 'inner cell mass', 'head start program']\n"
     ]
    }
   ],
   "source": [
    "with open('../data/libGrams5.pickle', 'rb') as f:\n",
    "    libGrams = pickle.load(f)\n",
    "    print(libGrams[:5])\n",
    "with open('../data/conGrams5.pickle', 'rb') as f:\n",
    "    conGrams = pickle.load(f)\n",
    "    print(conGrams[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(libGrams), len(conGrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hard look',\n",
       " 'corporate interests',\n",
       " 'critical funding',\n",
       " 'broken promises',\n",
       " 'safe drinking',\n",
       " 'religious persecution',\n",
       " 'work within',\n",
       " 'reconciliation package',\n",
       " 'new debt',\n",
       " 'budget supports']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "libGrams[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['necessary reforms',\n",
       " 'another attack',\n",
       " 'wrong message',\n",
       " 'particularly pleased',\n",
       " 'great strides',\n",
       " 'best possible',\n",
       " 'federal criminal',\n",
       " 'adversarial relationship',\n",
       " 'top rate',\n",
       " 'environmental concerns']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conGrams[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Data\n",
    "filter the original dataset for only those sentences that contain politically charged bigrams and lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keepSentence(label, text):\n",
    "    # get bigrams and lexicons\n",
    "    if len(text.split()) < 6:\n",
    "        return False\n",
    "    ngrams = list(getNgrams(text,n=2).keys()) + list(getNgrams(text,n=3).keys())\n",
    "    \n",
    "    # get the bigrams and lexicons that appear in the ideology lists\n",
    "    libNgramSet = set(ngrams).intersection(libGrams)\n",
    "    conNgramSet = set(ngrams).intersection(conGrams)\n",
    "    \n",
    "    # determine whether to keep the sentence\n",
    "    if label == 1:\n",
    "        return libNgramSet\n",
    "    elif label == -1:\n",
    "        return conNgramSet\n",
    "    else:\n",
    "        if libNgramSet or conNgramSet:\n",
    "            return False\n",
    "        else:\n",
    "            return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterText(df):\n",
    "    filteredText = []\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        label,text = df.label[i], df.text[i]\n",
    "        ngrams = keepSentence(label,text)\n",
    "        if ngrams:\n",
    "            filteredText.append((label, text, ngrams))\n",
    "            \n",
    "    return pd.DataFrame(filteredText, columns=['label','text','ngrams'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54830/54830 [00:25<00:00, 2127.24it/s]\n"
     ]
    }
   ],
   "source": [
    "df_filtered = filterText(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54830, 2), (2922, 3))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, df_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>ngrams</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>1326</td>\n",
       "      <td>1326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>213</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1383</td>\n",
       "      <td>1383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       text  ngrams\n",
       "label              \n",
       "-1     1326    1326\n",
       " 0      213     213\n",
       " 1     1383    1383"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [1\n",
      " 'the second question we will be asking will be : would you rather spend $ 7.9 billion on a ballistic missile defense program which has been tested time after time after time and has failed all of those tests , or would you rather spend that $ 7.8 billion on providing more security to our troops , body armor , personnel support equipment , and other protective gear for our troops , and providing more benefits to our veterans in this country ?'\n",
      " {'ballistic missile defense'}]\n",
      "1 [1\n",
      " 'they have been especially resistant to providing the adequate funding along the borders , especially the canadian border .'\n",
      " {'adequate funding'}]\n",
      "2 [-1\n",
      " 'the sponsors intend that such a conclusion would favor allowing the state court in which the action was originally filed to handle the litigation .'\n",
      " {'would favor'}]\n",
      "3 [1\n",
      " \"those of us on this side of the aisle believe we have a better approach , one that is fair to millions of americans and their families who get up every morning , put in a hard day 's work and are the very backbone of america 's economy and our communities .\"\n",
      " {'better approach'}]\n",
      "4 [-1\n",
      " 'there are many examples in louisiana and around this country that are competing , despite the regulatory burden , the tax burden and other added costs of doing business .'\n",
      " {'regulatory burden'}]\n",
      "5 [1\n",
      " 'she said : the united states offers protection in the form of asylum to individuals fleeing persecution in other nations .'\n",
      " {'fleeing persecution'}]\n",
      "6 [1\n",
      " 'that agenda includes protecting tax breaks for the very wealthy in this country .'\n",
      " {'tax breaks'}]\n",
      "7 [-1\n",
      " 'i do not want situations put upon our country where we see that , again , people from hollywood are saying , well , there is no such thing as mental illness , and therefore , we do not treat it .'\n",
      " {'mental illness'}]\n",
      "8 [1\n",
      " 'why would we increase the number of these individuals without adequate health care coverage ?'\n",
      " {'without adequate'}]\n",
      "9 [-1\n",
      " 'we have heard that 67 percent of all victims of sexual assault are juveniles .'\n",
      " {'sexual assault'}]\n",
      "10 [0\n",
      " 'well , i think maybe mr. immelt should look to the united states for the future of ge , and gm and other corporations should do the same .'\n",
      " True]\n",
      "11 [-1\n",
      " 'the standard we set for a war when we are at war with radical islam should not be the new standard set for america once that war is over .'\n",
      " {'radical islam'}]\n",
      "12 [1\n",
      " 'the policy president bush announced in august 2001 has limited access to stem cell lines and has stalled scientific progress .'\n",
      " {'president bush announced', 'scientific progress'}]\n",
      "13 [1\n",
      " 'all of this could have been avoided with the proper oversight and governance .'\n",
      " {'proper oversight'}]\n",
      "14 [1\n",
      " 'mr. chairman , the american people need us to enact legislation that will actually reduce the cost of gasoline and reduce our dependence on foreign oil .'\n",
      " {'american people need'}]\n",
      "15 [1\n",
      " 'americans are pouring their hearts out and their money out , and we are using their taxpayer dollars to send down to the affected areas , and rightfully so , without the proper oversight and without any real congressional review .'\n",
      " {'proper oversight'}]\n",
      "16 [-1\n",
      " \"165-09 , `` maintenance of delegation in respect to general authority over customs revenue functions vested in the secretary of the treasury , as set forth and defined in the homeland security act of 2002 , '' dated february 28 , 2003 , is rescinded .\"\n",
      " {'homeland security act'}]\n",
      "17 [1\n",
      " 'and then if that were not bad enough , they have included a nearly $ 2 billion bailout for these same companies .'\n",
      " {'bad enough'}]\n",
      "18 [-1\n",
      " 'while some are calling for suffocating pension funding rules which would place an incredible burden on employers who voluntarily offer retirement benefits , our bill makes certain not to tighten the rules so much that employers leave the defined benefit system altogether .'\n",
      " {'defined benefit system'}]\n",
      "19 [0 'all of the estate tax is paid by the wealthiest 2 percent .' True]\n"
     ]
    }
   ],
   "source": [
    "n = 20\n",
    "sample = df_filtered.sample(n)\n",
    "for i in range(n):\n",
    "    print(i, sample.iloc[i].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# savepath = r'../data'\n",
    "# with open(os.path.join(savepath, 'filteredConvote.pickle'), 'wb') as f:\n",
    "#     pickle.dump(df_filtered, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open('../data/filteredConvote5.pickle', 'wb') as f:\n",
    "    pickle.dump(df_filtered.loc[:,['label','text']], f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>-1</td>\n",
       "      <td>what it merely says is that in an instance whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>-1</td>\n",
       "      <td>in years past , when those of us on the subcom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>-1</td>\n",
       "      <td>i have here an april 26 story from the associa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2761</th>\n",
       "      <td>1</td>\n",
       "      <td>why close the doors to those who are injured b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>-1</td>\n",
       "      <td>finally , i must oppose this bill because it e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "1273     -1  what it merely says is that in an instance whe...\n",
       "1337     -1  in years past , when those of us on the subcom...\n",
       "1333     -1  i have here an april 26 story from the associa...\n",
       "2761      1  why close the doors to those who are injured b...\n",
       "1983     -1  finally , i must oppose this bill because it e..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/filteredConvote5.pickle', 'rb') as f:\n",
    "    test = pickle.load(f)\n",
    "test.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it is clear that there would be plenty of money to deal with the social security trust fund if the president were not using the social security trust fund as a slush fund to give tax cuts to the wealthiest people in america . \n",
      "\n",
      "this bill is another missed opportunity to take america into the future , to take america into the leadership around the world in energy production , energy innovation , and energy technology ; to create a new generation of important products , and a new generation of jobs . \n",
      "\n",
      "instead , these changes will make it harder for people legitimately fleeing persecution to prove their asylum claims and gain protection here . \n",
      "\n",
      "in it , congress provides the yearly resources needed to keep our families healthy , our children educated , our workers employed , and our most vulnerable citizens a productive part of our society . \n",
      "\n",
      "under the business records provision , section 215 of the patriot act , the bill provides that the government may seek a court order for `` any tangible item '' if law enforcement officials assert that the records are sought in an effort to obtain foreign intelligence or in a terrorism investigation . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in test[test.label == 1].sample(5).text.values:\n",
    "    print(s,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what do you do about private property rights ? \n",
      "\n",
      "on both the business records and delayed notification sections of the patriot act ( among others ) , the stance of the american civil liberties union and like-minded critics seems to have an ulterior motive . \n",
      "\n",
      "it will create a comprehensive national system for sex offender registration , improve information exchange between states when sex offenders move from state to state , and increase penalties for failing to comply with the registration law . \n",
      "\n",
      "i ask members to support the osha reform and in particular h.r. \n",
      "\n",
      "that legislation helped to streamline the intelligence community and tightened some asylum rules that allowed potential terrorists to remain in our country . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in test[test.label == -1].sample(5).text.values:\n",
    "    print(s,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let us look at what is going on in america today . \n",
      "\n",
      "andy grove , the founder of intel , predicts that the united states will lose the bulk of its information technology to jobs to china and india within the next decade . \n",
      "\n",
      "just yesterday , we learned that general motors is now going to cut back on another 25 , 000 good-paying jobs for american workers . \n",
      "\n",
      "let us pass this resolution . \n",
      "\n",
      "mr. speaker , parliamentary inquiry . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in test[test.label == 0].sample(5).text.values:\n",
    "    print(s,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
