{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/alex/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/alex/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package names to /home/alex/nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n",
      "[nltk_data] Downloading package opinion_lexicon to\n",
      "[nltk_data]     /home/alex/nltk_data...\n",
      "[nltk_data]   Package opinion_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import time, os, pickle\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords, names, opinion_lexicon\n",
    "from itertools import combinations, permutations\n",
    "from collections import Counter\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "# plt.style.use('ggplot')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('names')\n",
    "nltk.download('opinion_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# maybe later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseContent(text):\n",
    "    sents = sent_tokenize(text)\n",
    "    words = []\n",
    "    for sent in sents:\n",
    "        words.append([w.lower() for w in word_tokenize(sent)])\n",
    "    return sents, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_and_pickle(openpath, savepath):\n",
    "    df = pd.read_csv(openpath)\n",
    "    df['content'] = df.content + ' ' + df.title\n",
    "    df = df.loc[:,['publication','content']]\n",
    "    sentences = []\n",
    "    wordList = []\n",
    "    start = time.time()\n",
    "    for text in df.content:\n",
    "        sents, words = parseContent(text)\n",
    "        sentences.append(sents)\n",
    "        wordList.append(words)\n",
    "    print('runtime (min):', (time.time() - start) / 60)\n",
    "    df['sentences'] = sentences\n",
    "    df['words'] = wordList\n",
    "    df = df.loc[:,['publication','sentences','words']]\n",
    "    with open(savepath, 'wb') as f:\n",
    "        pickle.dump(df, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = pd.read_csv(r'../all-the-news/articles1.csv')\n",
    "# df2 = pd.read_csv(r'../all-the-news/articles2.csv')\n",
    "# df3 = pd.read_csv(r'../all-the-news/articles3.csv')\n",
    "opens = [\n",
    "    r'../all-the-news/articles1.csv',\n",
    "    r'../all-the-news/articles2.csv',\n",
    "    r'../all-the-news/articles3.csv'\n",
    "]\n",
    "saves = [\n",
    "    r'../data/news1_parsed.pickle',\n",
    "    r'../data/news2_parsed.pickle',\n",
    "    r'../data/news3_parsed.pickle'\n",
    "]\n",
    "for o,s in zip(opens, saves):\n",
    "    parse_and_pickle(o, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# current import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142570, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(r'../all-the-news/articles1.csv')\n",
    "df2 = pd.read_csv(r'../all-the-news/articles2.csv')\n",
    "df3 = pd.read_csv(r'../all-the-news/articles3.csv')\n",
    "df = df1.append(df2).append(df3)\n",
    "df.index = range(df.shape[0])\n",
    "df['content'] = df.content + ' ' + df.title\n",
    "df = df.loc[:,['publication','content']]\n",
    "del df1, df2, df3\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['New York Times', 'Breitbart', 'CNN', 'Business Insider',\n",
       "       'Atlantic', 'Fox News', 'Talking Points Memo', 'Buzzfeed News',\n",
       "       'National Review', 'New York Post', 'Guardian', 'NPR', 'Reuters',\n",
       "       'Vox', 'Washington Post'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.publication.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating new lexicons and bigrams for news set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Breitbart', 'CNN', 'Fox News', 'Talking Points Memo',\n",
       "       'National Review', 'Reuters', 'Vox'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pubs = ['Breitbart', 'CNN', 'Fox News', 'Talking Points Memo','National Review','Reuters','Vox']\n",
    "idx = [i for i in range(df.shape[0]) if df.publication.iloc[i] in pubs]\n",
    "df = df.iloc[idx]\n",
    "df.publication.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66697, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual labels from MBFC\n",
    "bias_dict = {\n",
    "    'New York Times': 'left-center',\n",
    "    'Breitbart': 'extreme-right',\n",
    "    'CNN': 'left',\n",
    "    'Business Insider': 'left-center',\n",
    "    'Atlantic': 'left-center',\n",
    "    'Fox News': 'right',\n",
    "    'Talking Points Memo': 'left',\n",
    "    'Buzzfeed News': 'left-center',\n",
    "    'National Review': 'right',\n",
    "    'New York Post': 'right-center',\n",
    "    'Guardian': 'left-center',\n",
    "    'NPR': 'left-center',\n",
    "    'Reuters': 'neutral',\n",
    "    'Vox': 'left',\n",
    "    'Washington Post': 'left-center'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York Times liberal\n",
      "Breitbart conservative\n",
      "CNN liberal\n",
      "Business Insider liberal\n",
      "Atlantic liberal\n",
      "Fox News conservative\n",
      "Talking Points Memo liberal\n",
      "Buzzfeed News liberal\n",
      "National Review conservative\n",
      "New York Post conservative\n",
      "Guardian liberal\n",
      "NPR liberal\n",
      "Reuters neutral\n",
      "Vox liberal\n",
      "Washington Post liberal\n"
     ]
    }
   ],
   "source": [
    "# simplified labels\n",
    "for k,v in bias_dict.items():\n",
    "    if 'left' in v:\n",
    "        bias_dict[k] = 'liberal'\n",
    "    elif 'right' in v:\n",
    "        bias_dict[k] = 'conservative'\n",
    "    else:\n",
    "        bias_dict[k] = 'neutral'\n",
    "for k,v in bias_dict.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['publication', 'content'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = [bias_dict[p] for p in df.publication.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['publication', 'content', 'label'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publication</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Breitbart</th>\n",
       "      <td>23781</td>\n",
       "      <td>23781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>11488</td>\n",
       "      <td>11488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fox News</th>\n",
       "      <td>4354</td>\n",
       "      <td>4354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>National Review</th>\n",
       "      <td>6203</td>\n",
       "      <td>6203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reuters</th>\n",
       "      <td>10709</td>\n",
       "      <td>10710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Talking Points Memo</th>\n",
       "      <td>5213</td>\n",
       "      <td>5214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vox</th>\n",
       "      <td>4947</td>\n",
       "      <td>4947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     content  label\n",
       "publication                        \n",
       "Breitbart              23781  23781\n",
       "CNN                    11488  11488\n",
       "Fox News                4354   4354\n",
       "National Review         6203   6203\n",
       "Reuters                10709  10710\n",
       "Talking Points Memo     5213   5214\n",
       "Vox                     4947   4947"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('publication').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publication</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>conservative</th>\n",
       "      <td>34338</td>\n",
       "      <td>34338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal</th>\n",
       "      <td>21649</td>\n",
       "      <td>21648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>10710</td>\n",
       "      <td>10709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              publication  content\n",
       "label                             \n",
       "conservative        34338    34338\n",
       "liberal             21649    21648\n",
       "neutral             10710    10709"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into liberal and conservative\n",
    "lib = df.loc[df.label == 'liberal']\n",
    "con = df.loc[df.label == 'conservative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a helper function to pull the bigrams\n",
    "def getBigrams(text, stops, ops=None):\n",
    "    '''return all bigrams in a Counter'''\n",
    "    def criteria(word):\n",
    "        if len(word) > 1 and word not in stops:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "            \n",
    "    # intialize counter\n",
    "    bigrams = Counter()\n",
    "    \n",
    "    # tokenize text\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # filter punctuation and single letter words\n",
    "    words = [w.lower() for w in words]\n",
    "    \n",
    "    # throw out sentences with less than two words\n",
    "    if len(words) < 2:\n",
    "        return bigrams\n",
    "    \n",
    "    # add bigrams to Counter\n",
    "    for i in range(len(words) - 1):\n",
    "        b = ' '.join((words[i], words[i+1]))\n",
    "        if criteria(words[i]) and criteria(words[i+1]):\n",
    "            if ops:\n",
    "                if words[i] in ops or words[i+1] in ops:\n",
    "                    bigrams[b] += 1\n",
    "            else:\n",
    "                bigrams[b] += 1\n",
    "        \n",
    "    return bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops = [w.lower() for w in stopwords.words('english')] + \\\n",
    "['trump', 'good','great','bad','pretty','covering','writer',\n",
    " 'author','like','news','follow','tv','said','could','would',\n",
    " 'really','best','journalist','journalists','commentator']\n",
    "stops[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops = opinion_lexicon.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "men = [w.lower() for w in names.words('male.txt')]\n",
    "women = [w.lower() for w in names.words('female.txt')]\n",
    "stopNames = men + women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['breitbart',\n",
       " 'cnn',\n",
       " 'fox',\n",
       " 'news',\n",
       " 'talking',\n",
       " 'points',\n",
       " 'memo',\n",
       " 'national',\n",
       " 'review',\n",
       " 'reuters',\n",
       " 'vox']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # stops2 = [\n",
    "# #     'breitbart','twitter','facebook','follow','hudson','sirius',\n",
    "# #     'author','nussbaum','hanchett','foxnews','share article','hawkins',\n",
    "# #     'cnn','join','said','told','like','tells','latest',':','.','share',\n",
    "# #     'klein','could','really','would'\n",
    "# # ]\n",
    "# stops2 = [\n",
    "#     'twitter','facebook','follow','sirius','author',\n",
    "#     'share','cnn','join','said','told','like','tells',\n",
    "#     'latest',':','.','could','really','would','good','bad',\n",
    "#     'editor'\n",
    "# ]\n",
    "stops3 = []\n",
    "for p in df.publication.unique():\n",
    "    stops3.extend(p.lower().split())\n",
    "stops3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(stops), len(stops2), len(stopNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8154"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stops.extend(stops2)\n",
    "stops.extend(stops3)\n",
    "stops.extend(stopNames)\n",
    "len(stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = set(stops)\n",
    "ops = set(ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7781, 6786)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stops), len(ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21649/21649 [03:04<00:00, 59.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0722961107889812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# libBigrams = Counter()\n",
    "libBigrams3 = Counter()\n",
    "for pub,content,_ in tqdm(lib.values):\n",
    "    try:\n",
    "        sents = sent_tokenize(content)\n",
    "    except:\n",
    "        continue\n",
    "    for text in sents:\n",
    "        libBigrams3.update(getBigrams(text, stops, ops=ops))\n",
    "print((time.time() - start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('white house', 1360),\n",
       " ('united states', 1256),\n",
       " ('new york', 1040),\n",
       " ('health care', 655),\n",
       " ('supreme court', 444),\n",
       " ('barack obama', 435),\n",
       " ('north korea', 399),\n",
       " ('obama administration', 381),\n",
       " ('last year', 369),\n",
       " ('last week', 364)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "libBigrams.most_common()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('supreme court', 3410),\n",
       " ('vice president', 1622),\n",
       " ('affordable care', 1244),\n",
       " ('sexual assault', 1033),\n",
       " ('look like', 807),\n",
       " ('intelligence committee', 801),\n",
       " ('looks like', 791),\n",
       " ('freedom caucus', 740),\n",
       " ('feel like', 715),\n",
       " ('criminal justice', 675)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "libBigrams2.most_common()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('white house', 10173),\n",
       " ('united states', 8914),\n",
       " ('new york', 7696),\n",
       " ('u. s.', 7549),\n",
       " ('health care', 4613),\n",
       " ('supreme court', 3410),\n",
       " ('north korea', 3175),\n",
       " ('barack obama', 3038),\n",
       " ('last year', 2856),\n",
       " ('last week', 2854)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "libBigrams3.most_common()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276255"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(libBigrams2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/libGrams_news2_unfiltered.pickle', 'wb') as f:\n",
    "#     pickle.dump(libBigrams, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/libGrams_news2_unfiltered.pickle', 'rb') as f:\n",
    "#     libBigrams = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(libBigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34338/34338 [03:47<00:00, 151.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.789326004187266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# conBigrams = Counter()\n",
    "conBigrams3 = Counter()\n",
    "for content in tqdm(con.content.values):\n",
    "    try:\n",
    "        sents = sent_tokenize(content)\n",
    "    except:\n",
    "        continue\n",
    "    for text in sents:\n",
    "        conBigrams3.update(getBigrams(text, stops,ops=ops))\n",
    "print((time.time() - start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conBigrams.most_common()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('supreme court', 4400),\n",
       " ('vice president', 1795),\n",
       " ('free speech', 1669),\n",
       " ('illegal immigrants', 1524),\n",
       " ('illegal aliens', 1138),\n",
       " ('fake news', 1115),\n",
       " ('illegal immigration', 922),\n",
       " ('america great', 823),\n",
       " ('siriusxm patriot', 808),\n",
       " ('would like', 778)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conBigrams2.most_common()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('u. s.', 22067),\n",
       " ('united states', 11775),\n",
       " ('new york', 10648),\n",
       " ('white house', 7892),\n",
       " ('president obama', 4971),\n",
       " ('supreme court', 4400),\n",
       " ('barack obama', 4054),\n",
       " ('obama administration', 3875),\n",
       " ('last year', 3605),\n",
       " ('last week', 3514)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conBigrams3.most_common()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/conGrams_news2_unfiltered.pickle', 'wb') as f:\n",
    "#     pickle.dump(conBigrams, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/conGrams_news2_unfiltered.pickle', 'rb') as f:\n",
    "#     conBigrams = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "323391"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(conBigrams2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the 1000 most common liberal and conservative bigrams\n",
    "# commonCon = [b[0] for b in conBigrams.most_common()[:1000]]\n",
    "# commonLib = [b[0] for b in libBigrams.most_common()[:1000]]\n",
    "commonCon3 = [b[0] for b in conBigrams3.most_common()[:1000]]\n",
    "commonLib3 = [b[0] for b in libBigrams3.most_common()[:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_bigrams = ['doctor strange','fury road','gold medals','mad men',\n",
    "                  'stranger things','little lies','lose weight',\n",
    "                  'world champion','premier league','walking dead',\n",
    "                  'weight loss','grand slam','science fiction','right now.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the bigrams for each ideology that appear in the top 1000 of that ideology and not in the top 1000 of the other\n",
    "# libBigrams_filtered = [(w,libBigrams[w]) for w in commonLib if w not in commonCon]\n",
    "libBigrams_filtered3 = [(w,libBigrams3[w]) for w in commonLib3 if w not in commonCon3 and w not in remove_bigrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "402"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(libBigrams_filtered3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 100 liberal bigrams:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('us intelligence', 369),\n",
       " ('fast facts', 299),\n",
       " ('opioid epidemic', 186),\n",
       " ('top democrat', 178),\n",
       " ('health reform', 157),\n",
       " ('lethal injection', 134),\n",
       " ('budget reconciliation', 116),\n",
       " ('chronic pain', 111),\n",
       " ('us supreme', 110),\n",
       " ('lead poisoning', 109),\n",
       " ('intelligence committees', 107),\n",
       " ('prison sentences', 101),\n",
       " ('rights advocates', 99),\n",
       " ('poverty line', 97),\n",
       " ('provocative narrative', 95),\n",
       " ('undocumented immigrant', 88),\n",
       " ('reconciliation process', 86),\n",
       " ('patriot act', 86),\n",
       " ('lose coverage', 84),\n",
       " ('excessive force', 81),\n",
       " ('lead exposure', 80),\n",
       " ('crude oil', 79),\n",
       " ('top republicans', 78),\n",
       " ('fatal shooting', 77),\n",
       " ('car bomb', 74),\n",
       " ('stars hollow', 74),\n",
       " ('increased risk', 73),\n",
       " ('sick people', 71),\n",
       " ('gas attack', 71),\n",
       " ('top white', 70),\n",
       " ('bigger problem', 70),\n",
       " ('plane crash', 69),\n",
       " ('american crime', 68),\n",
       " ('corruption scandal', 67),\n",
       " ('yet clear', 67),\n",
       " ('extreme poverty', 67),\n",
       " ('assault allegations', 65),\n",
       " ('still unclear', 65),\n",
       " ('possible collusion', 65),\n",
       " ('broadcasts ideal', 64),\n",
       " ('clearly describe', 64),\n",
       " ('serial killer', 64),\n",
       " ('hot air', 64),\n",
       " ('involuntary manslaughter', 63),\n",
       " ('fair housing', 63),\n",
       " ('brain injury', 62),\n",
       " ('people die', 62),\n",
       " ('peace agreement', 62),\n",
       " ('murder trial', 62),\n",
       " ('conservative house', 61),\n",
       " ('top republican', 61),\n",
       " ('racial resentment', 61),\n",
       " ('million undocumented', 60),\n",
       " ('uninsured rate', 60),\n",
       " ('british intelligence', 59),\n",
       " ('nearly enough', 59),\n",
       " ('strike group', 59),\n",
       " ('top stories', 59),\n",
       " ('us strike', 58),\n",
       " ('heroin epidemic', 58),\n",
       " ('indecent assault', 58),\n",
       " ('top advisers', 57),\n",
       " ('syrian conflict', 56),\n",
       " ('important step', 56),\n",
       " ('killed two', 56),\n",
       " ('skin cancer', 56),\n",
       " ('lead levels', 56),\n",
       " ('election interference', 55),\n",
       " ('affordable housing', 55),\n",
       " ('seems clear', 55),\n",
       " ('cancer patients', 55),\n",
       " ('cervical cancer', 55),\n",
       " ('less clear', 55),\n",
       " ('also killed', 54),\n",
       " ('murder charges', 54),\n",
       " ('lifetime achievement', 54),\n",
       " ('top adviser', 53),\n",
       " ('higher risk', 53),\n",
       " ('outstanding performance', 53),\n",
       " ('alarm bells', 52),\n",
       " ('bomb threat', 52),\n",
       " ('political crisis', 52),\n",
       " ('assault cases', 52),\n",
       " ('military intelligence', 51),\n",
       " ('issues related', 51),\n",
       " ('heart failure', 51),\n",
       " ('better call', 51),\n",
       " ('nervous system', 51),\n",
       " ('later died', 51),\n",
       " ('public defender', 51),\n",
       " ('fair amount', 51),\n",
       " ('greater risk', 50),\n",
       " ('become clear', 50),\n",
       " ('becomes clear', 50),\n",
       " ('peace plan', 50),\n",
       " ('lgbtq advocates', 50),\n",
       " ('key issue', 49),\n",
       " ('risk factors', 49),\n",
       " ('murder charge', 49),\n",
       " ('voted illegally', 49)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('top 100 liberal bigrams:')\n",
    "sorted(libBigrams_filtered3,key=lambda x: -x[1])[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conservative bigrams also had weird 'amp nbsp' HTML tags so remove those\n",
    "# conBigrams_filtered = [(w,conBigrams[w]) for w in commonCon if w not in commonLib]\n",
    "conBigrams_filtered3 = [(w,conBigrams3[w]) for w in commonCon3 if w not in commonLib3 and w not in remove_bigrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(conBigrams_filtered3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 100 conservative bigrams:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('illegal aliens', 1138),\n",
       " ('siriusxm patriot', 808),\n",
       " ('illegal alien', 624),\n",
       " ('patriot 125', 598),\n",
       " ('illegal immigrant', 482),\n",
       " ('criminal aliens', 375),\n",
       " ('migrant crisis', 366),\n",
       " ('popular weekend', 327),\n",
       " ('patriot channel', 316),\n",
       " ('hard truths', 298),\n",
       " ('19 hard', 283),\n",
       " ('limited government', 206),\n",
       " ('islamic terror', 203),\n",
       " ('twin falls', 199),\n",
       " ('suppression cost', 175),\n",
       " ('liberal elite', 169),\n",
       " ('snarky opinions', 159),\n",
       " ('dangerous faggot', 156),\n",
       " ('free beacon', 155),\n",
       " ('conservative principles', 151),\n",
       " ('violent campus', 139),\n",
       " ('award winning', 138),\n",
       " ('free expression', 137),\n",
       " ('free markets', 134),\n",
       " ('million illegal', 126),\n",
       " ('politically incorrect', 126),\n",
       " ('real clear', 124),\n",
       " ('shocking speed', 124),\n",
       " ('clear politics', 121),\n",
       " ('certain death', 116),\n",
       " ('criminal illegal', 114),\n",
       " ('sex attacks', 111),\n",
       " ('work permits', 110),\n",
       " ('cheap labor', 109),\n",
       " ('free movement', 106),\n",
       " ('derangement syndrome', 104),\n",
       " ('gross negligence', 103),\n",
       " ('die welt', 102),\n",
       " ('media bias', 101),\n",
       " ('illegal migrants', 99),\n",
       " ('siriusxm vice', 99),\n",
       " ('criminal prosecution', 99),\n",
       " ('mass murder', 98),\n",
       " ('civil disobedience', 98),\n",
       " ('amendment right', 97),\n",
       " ('radical islamists', 96),\n",
       " ('point lead', 95),\n",
       " ('progressive left', 92),\n",
       " ('currency manipulation', 92),\n",
       " ('xm patriot', 92),\n",
       " ('human dignity', 88),\n",
       " ('islamist terror', 87),\n",
       " ('free enterprise', 86),\n",
       " ('wrong side', 85),\n",
       " ('medical progress', 85),\n",
       " ('us safe', 84),\n",
       " ('stronger together', 84),\n",
       " ('lead among', 84),\n",
       " ('s. illegally', 83),\n",
       " ('hunger strike', 83),\n",
       " ('criminal alien', 83),\n",
       " ('protection act', 82),\n",
       " ('revolutionary guard', 81),\n",
       " ('one wonders', 81),\n",
       " ('radical islamist', 81),\n",
       " ('individual right', 81),\n",
       " ('free society', 81),\n",
       " ('brussels attacks', 81),\n",
       " ('entitlement reform', 80),\n",
       " ('islamic extremists', 79),\n",
       " ('protect american', 79),\n",
       " ('state terror', 79),\n",
       " ('wrong direction', 78),\n",
       " ('hate group', 76),\n",
       " ('term limits', 76),\n",
       " ('sampling error', 76),\n",
       " ('progressive boomeranga', 76),\n",
       " ('bless america', 75),\n",
       " ('alleged rape', 75),\n",
       " ('liberal bias', 74),\n",
       " ('aborted babies', 74),\n",
       " ('dirty tricks', 74),\n",
       " ('conservative leaders', 73),\n",
       " ('individual liberty', 73),\n",
       " ('dead heat', 73),\n",
       " ('drunk driving', 72),\n",
       " ('work force', 72),\n",
       " ('top ten', 71),\n",
       " ('enough delegates', 71),\n",
       " ('dictator bashar', 70),\n",
       " ('alien crime', 69),\n",
       " ('faux outrage', 69),\n",
       " ('savior generals', 69),\n",
       " ('gang rape', 68),\n",
       " ('welfare benefits', 68),\n",
       " ('radical left', 68),\n",
       " ('political issues', 67),\n",
       " ('alt right', 67),\n",
       " ('every issue', 67),\n",
       " ('delegate lead', 67)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('top 100 conservative bigrams:')\n",
    "sorted(conBigrams_filtered3,key=lambda x: -x[1])[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep just the bigrams and drop the count data\n",
    "libGrams = [k for k,v in sorted(libBigrams_filtered3,key=lambda x: -x[1])]\n",
    "conGrams = [k for k,v in sorted(conBigrams_filtered3,key=lambda x: -x[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep just the bigrams and drop the count data\n",
    "# libGrams = [k for k,v in libBigrams_filtered]\n",
    "# conGrams = [k for k,v in conBigrams_filtered if 'national review' not in k and 'awr hawkins' not in k] # getting rid of 'national review'\n",
    "\n",
    "with open('../data/libGrams_news_withOpinion.pickle', 'wb') as f:\n",
    "    pickle.dump(libGrams, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open('../data/conGrams_news_withOpinion.pickle', 'wb') as f:\n",
    "    pickle.dump(conGrams, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load liberal and conservative bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['us intelligence', 'fast facts', 'opioid epidemic', 'top democrat', 'health reform']\n",
      "['illegal aliens', 'siriusxm patriot', 'illegal alien', 'patriot 125', 'illegal immigrant']\n"
     ]
    }
   ],
   "source": [
    "# savepath = r'../data'\n",
    "# with open(os.path.join(savepath, 'libGrams_news.pickle'), 'rb') as f:\n",
    "#     test = pickle.load(f)\n",
    "#     print(test[:5])\n",
    "# with open(os.path.join(savepath, 'conGrams_news.pickle'), 'rb') as f:\n",
    "#     test = pickle.load(f)\n",
    "#     print(test[:5])\n",
    "with open('../data/libGrams_news_withOpinion.pickle', 'rb') as f:\n",
    "    libGrams = pickle.load(f)\n",
    "    print(libGrams[:5])\n",
    "with open('../data/conGrams_news_withOpinion.pickle', 'rb') as f:\n",
    "    conGrams = pickle.load(f)\n",
    "    print(conGrams[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine most common lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a helper function to pull the bigrams\n",
    "def getLexicons(text, stops):\n",
    "    '''return all bigrams in a Counter'''\n",
    "    # intialize counter\n",
    "    lexicons = Counter()\n",
    "    \n",
    "    # tokenize text\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # filter punctuation and single letter words\n",
    "    words = [w.lower() for w in words]\n",
    "    \n",
    "    # add lexicons to Counter\n",
    "    for w in words:\n",
    "        if w not in stops and len(w) > 1 and not w.isnumeric():\n",
    "            lexicons[w] += 1\n",
    "        \n",
    "    return lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179, 22)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stops), len(stops2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops.extend(stops2)\n",
    "len(stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'id', 'title', 'publication', 'author', 'date', 'year',\n",
       "       'month', 'url', 'content', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lib.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime (min): 2.987015656630198\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "libLexicons = Counter()\n",
    "for text in lib.content:\n",
    "    libLexicons.update(getLexicons(text, stops))\n",
    "print('runtime (min):', (time.time() - start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trump', 82297),\n",
       " ('people', 45281),\n",
       " ('would', 42706),\n",
       " ('one', 42477),\n",
       " ('president', 30646),\n",
       " ('also', 30267),\n",
       " ('new', 30187),\n",
       " ('us', 29867),\n",
       " ('could', 24097),\n",
       " ('time', 23036)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "libLexicons.most_common()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime (min): 3.5280917326609296\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "conLexicons = Counter()\n",
    "for text in con.content:\n",
    "    conLexicons.update(getLexicons(text, stops))\n",
    "print('runtime (min):', (time.time() - start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trump', 109740),\n",
       " ('clinton', 50981),\n",
       " ('would', 49631),\n",
       " ('people', 47887),\n",
       " ('one', 46192),\n",
       " ('president', 40427),\n",
       " ('new', 35565),\n",
       " ('also', 32915),\n",
       " ('state', 31321),\n",
       " ('news', 30307)]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conLexicons.most_common()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "most of these bigrams are neutral. Grab the 1000 most common from each ideology, then filter out any that appear in the other ideology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the 1000 most common liberal and conservative lexicons\n",
    "commonCon = [L[0] for L in conLexicons.most_common()[:1000]]\n",
    "commonLib = [L[0] for L in libLexicons.most_common()[:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the bigrams for each ideology that appear in the top 1000 of that ideology and not in the top 1000 of the other\n",
    "libLexicons_filtered = [(w,libLexicons[w]) for w in commonLib[:1000] if w not in commonCon and w.isalpha()]\n",
    "# conservative bigrams also had weird 'amp nbsp' HTML tags so remove those\n",
    "conLexicons_filtered = [(w,conLexicons[w]) for w in commonCon[:1000] if w not in commonLib and w.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129, 124)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(libLexicons_filtered), len(conLexicons_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep just the bigrams and drop the count data\n",
    "libCons = [k for k,v in libLexicons_filtered]\n",
    "conCons = [k for k,v in conLexicons_filtered]\n",
    "savepath = r'../data'\n",
    "\n",
    "with open(os.path.join(savepath, 'libCons_news.pickle'), 'wb') as f:\n",
    "    pickle.dump(libCons, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(os.path.join(savepath, 'conCons_news.pickle'), 'wb') as f:\n",
    "    pickle.dump(conCons, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['season', 'flynn', 'pretty', 'food', 'science']\n",
      "['islamic', 'pic', 'illegal', 'article', 'com']\n"
     ]
    }
   ],
   "source": [
    "savepath = r'../data'\n",
    "# with open(os.path.join(savepath, 'libCons_news.pickle'), 'rb') as f:\n",
    "#     test = pickle.load(f)\n",
    "#     print(test[:5])\n",
    "# with open(os.path.join(savepath, 'conCons_news.pickle'), 'rb') as f:\n",
    "#     test = pickle.load(f)\n",
    "#     print(test[:5])\n",
    "with open(os.path.join(savepath, 'libCons_news.pickle'), 'rb') as f:\n",
    "    libCons = pickle.load(f)\n",
    "    print(libCons[:5])\n",
    "with open(os.path.join(savepath, 'conCons_news.pickle'), 'rb') as f:\n",
    "    conCons = pickle.load(f)\n",
    "    print(conCons[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reload Data and test sentence filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142570, 2)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(r'../all-the-news/articles1.csv')\n",
    "df2 = pd.read_csv(r'../all-the-news/articles2.csv')\n",
    "df3 = pd.read_csv(r'../all-the-news/articles3.csv')\n",
    "df = df1.append(df2).append(df3)\n",
    "df.index = range(df.shape[0])\n",
    "df['content'] = df.content + ' ' + df.title\n",
    "df = df.loc[:,['publication','content']]\n",
    "del df1, df2, df3\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = [bias_dict[p] for p in df.publication.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['publication', 'content', 'label'], dtype='object')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractContent(row, libGrams, conGrams):\n",
    "    sentList = []\n",
    "    try:\n",
    "        sentences = sent_tokenize(row.content)\n",
    "    except:\n",
    "        return sentList\n",
    "#     sentences.append(row.title)\n",
    "    for s in sentences:\n",
    "        if len(s) < 5:\n",
    "            continue\n",
    "        try:\n",
    "            words = word_tokenize(s)\n",
    "            words = [w.lower() for w in words]\n",
    "            bigrams = []\n",
    "            for i in range(len(words) - 1):\n",
    "                bigrams.append(' '.join((words[i], words[i+1])))\n",
    "        except:\n",
    "            continue\n",
    "#         libConsPresent = set(words).intersection(libCons)\n",
    "        libGramsPresent = set(bigrams).intersection(libGrams)\n",
    "#         conConsPresent = set(words).intersection(conCons)\n",
    "        conGramsPresent = set(bigrams).intersection(conGrams)\n",
    "#         libNum = len(libConsPresent) + len(libGramsPresent)\n",
    "#         conNum = len(conConsPresent) + len(conGramsPresent)\n",
    "        libNum = len(libGramsPresent)\n",
    "        conNum = len(conGramsPresent)\n",
    "        if libNum == conNum:\n",
    "            label = 'neutral'\n",
    "        elif libNum > conNum:\n",
    "            label = 'liberal'\n",
    "        else:\n",
    "            label = 'conservative'\n",
    "        if libGramsPresent:\n",
    "            grams = libGramsPresent\n",
    "        elif conGramsPresent:\n",
    "            grams = conGramsPresent\n",
    "        else:\n",
    "            grams = set()\n",
    "        sentList.append((label, s, grams))\n",
    "    return sentList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 109.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30, 3)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing\n",
    "sample = df.sample(100)\n",
    "sents = []\n",
    "for i in tqdm(range(100)):\n",
    "    sentList = extractContent(sample.iloc[i], libGrams[:100], conGrams[:100])\n",
    "    sents.extend(sentList)\n",
    "# df2 = pd.DataFrame(sents, columns=['label','text'])\n",
    "df2 = pd.DataFrame(sents, columns=['label','text','grams'])\n",
    "df2[df2.label != 'neutral'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>grams</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>conservative</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>3912</td>\n",
       "      <td>3912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              text  grams\n",
       "label                    \n",
       "conservative    16     16\n",
       "liberal         14     14\n",
       "neutral       3912   3912"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['conservative' 'That’s not keeping us safe.' {'us safe'}]\n",
      "1 ['conservative'\n",
      " 'A jury in Teesside Crown Court in North Yorkshire, England, found    Mohammed Zaman guilty of manslaughter and gross negligence because he switched out almond powder for a cheaper ground nut mix containing peanuts,  .'\n",
      " {'gross negligence'}]\n",
      "2 ['liberal'\n",
      " ' Paul Ryan, the top Republican in the U. S. Congress, says he talks to Donald Trump often, but the   has tapped a   lawmaker from western New York to be his eyes and ears among congressional Republicans.'\n",
      " {'top republican'}]\n",
      "3 ['liberal' '9 [  ] event is getting less clear with time.' {'less clear'}]\n",
      "4 ['liberal'\n",
      " 'Remember: 83 percent of city schools had water fixtures with lead levels above federal safety limits.'\n",
      " {'lead levels'}]\n",
      "5 ['liberal'\n",
      " 'While the Obama administration had clear guidance prioritizing deportation of   criminals, an executive order signed by Trump in his first week set up enforcement priorities that could include virtually any undocumented immigrant living in the US.'\n",
      " {'undocumented immigrant'}]\n",
      "6 ['conservative'\n",
      " 'ICE only conducts targeted enforcement of criminal aliens and other individuals who are in violation of our nation’s immigration laws.” DHS secretary John Kelly told reporters at San Ysidro Port of Entry between San Diego and Tijuana on Friday that his department isn’t ”rounding anyone up.” ”The people that ICE apprehend are people who are illegal and then some,” he said.'\n",
      " {'criminal aliens'}]\n",
      "7 ['conservative'\n",
      " 'But the Islamist terror group has yet to say anything about the bombing.'\n",
      " {'islamist terror'}]\n",
      "8 ['liberal' '1 percent belonged to families living below the poverty line.'\n",
      " {'poverty line'}]\n",
      "9 ['liberal'\n",
      " 'The organization provides more than 3, 000 units of affordable housing.'\n",
      " {'affordable housing'}]\n",
      "10 ['liberal'\n",
      " 'He called the top Democrat in the land the “head clown” and accused the American intelligence community of acting like Nazis.'\n",
      " {'top democrat'}]\n",
      "11 ['liberal'\n",
      " 'In addition to winning the Electoral College in a landslide, I won the popular vote if you deduct the millions of people who voted illegally.'\n",
      " {'voted illegally'}]\n",
      "12 ['liberal'\n",
      " 'That was the year the Supreme Court vacated a judgment against Victor Hugo Saldano, whose capital murder trial included testimony from Quijano that Saldano’s Hispanic heritage increased the likelihood that he posed a danger.'\n",
      " {'murder trial'}]\n",
      "13 ['liberal'\n",
      " '”It’s important for me to finish my job as   until the very last moment of my mandate.”  (Reporting by Jean Yoon and Michelle Nichols; additional reporting by Tony Munroe in Seoul; editing by Grant McCool) CARACAS   government supporters burst into Venezuela’s   congress on Wednesday, witnesses said, attacking and besieging lawmakers in the latest   of violence during a political crisis.'\n",
      " {'political crisis'}]\n",
      "14 ['liberal'\n",
      " 'Two others were previously found guilty and later died in prison.'\n",
      " {'later died'}]\n",
      "15 ['liberal'\n",
      " 'Reporters who traveled to Britain for Trump’s visit were told that the candidate would possibly make a stop at his course near Aberdeen on Saturday  —   but as of late Friday night, it was still unclear whether the event would occur.'\n",
      " {'still unclear'}]\n",
      "16 ['conservative'\n",
      " 'The Salvadoran illegal immigrant is expected to go before U. S. District Judge Ricardo Hinojosa next week for a formal hearing.'\n",
      " {'illegal immigrant'}]\n",
      "17 ['conservative'\n",
      " 'Child Porn on Immigrant’s Phone by ildefonso ortiz on Scribd,  Ildefonso Ortiz is an award winning journalist with Breitbart Texas.'\n",
      " {'award winning'}]\n",
      "18 ['conservative'\n",
      " 'Illegal Immigrant Caught at Border with Child Porn of 4-Year-Olds on Phone'\n",
      " {'illegal immigrant'}]\n",
      "19 ['conservative'\n",
      " 'He says he will embrace free enterprise, will be a a country that says life begins at conception, be a country where marriage is between one man and one woman, and where our rights come from our Creator.'\n",
      " {'free enterprise'}]\n",
      "20 ['conservative'\n",
      " 'He wants Carson to tell voters something that is not politically incorrect.'\n",
      " {'politically incorrect'}]\n",
      "21 ['conservative'\n",
      " 'He says   programs have become a lifestyle and he says “poverty is free enterprise not reaching people.'\n",
      " {'free enterprise'}]\n",
      "22 ['conservative'\n",
      " 'Trump wants to know how Bush kept us safe when the World Trade Centers came down while Bush was president.'\n",
      " {'us safe'}]\n",
      "23 ['conservative'\n",
      " 'He says his dad is the greatest person alive and his brother was building a security apparatus to keep us safe while Trump was building a reality tv empire.'\n",
      " {'us safe'}]\n",
      "24 ['conservative'\n",
      " '” He says someone, like Scalia, who is a “lover of liberty” and a “believer of limited government” should be nominated.'\n",
      " {'limited government'}]\n",
      "25 ['conservative'\n",
      " 'Breitbart News Daily airs on SiriusXM Patriot 125 weekdays from 6:00 a. m. to 9:00 a. m. Eastern.'\n",
      " {'siriusxm patriot', 'patriot 125'}]\n",
      "26 ['conservative'\n",
      " 'now declares that he doesn’t expect Trump to build a border wall or deport 11 million illegal immigrants  —   the cornerstones of Trump’s primary campaign.'\n",
      " {'million illegal'}]\n",
      "27 ['conservative'\n",
      " '’ ’   He supports small government, respects capitalism, is     emphasizes the need for entitlement reform, and   wants to repeal and replace the Affordable Care Act.'\n",
      " {'entitlement reform'}]\n",
      "28 ['liberal'\n",
      " 'Sessions contends a spike in violence in some big cities and the nation’s opioid epidemic show the need for a return to tougher tactics.'\n",
      " {'opioid epidemic'}]\n",
      "29 ['liberal'\n",
      " '“The opioid and heroin epidemic is a contributor to the recent surge of violent crime in America,” Sessions said in remarks prepared for a Thursday speech in Charleston, West Virginia.'\n",
      " {'heroin epidemic'}]\n"
     ]
    }
   ],
   "source": [
    "for i,t in enumerate(df2[df2.label != 'neutral'].values):\n",
    "    print(i,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['New York Times', 'Breitbart', 'CNN', 'Business Insider',\n",
       "       'Atlantic', 'Fox News', 'Talking Points Memo', 'Buzzfeed News',\n",
       "       'National Review', 'New York Post', 'Guardian', 'NPR', 'Reuters',\n",
       "       'Vox', 'Washington Post'], dtype=object)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.publication.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractSentences(df, libGrams, conGrams):\n",
    "    output = []\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        sentList = extractContent(df.iloc[i], libGrams, conGrams)\n",
    "        output.extend(sentList)\n",
    "    df = pd.DataFrame(output, columns=['label','text','grams'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# df1 = extractSentences(df,50)\n",
    "# print('runtime (min): ', (time.time() - start) / 60)\n",
    "# df1.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 142570/142570 [22:17<00:00, 106.62it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>grams</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>conservative</th>\n",
       "      <td>19462</td>\n",
       "      <td>19462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal</th>\n",
       "      <td>23106</td>\n",
       "      <td>23106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>5058369</td>\n",
       "      <td>5058369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 text    grams\n",
       "label                         \n",
       "conservative    19462    19462\n",
       "liberal         23106    23106\n",
       "neutral       5058369  5058369"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start = time.time()\n",
    "df2 = extractSentences(df, libGrams[:100], conGrams[:100])\n",
    "# print('runtime (min): ', (time.time() - start) / 60)\n",
    "df2.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label', 'text', 'grams'], dtype='object')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['liberal'\n",
      " 'Mateen “made a pledge of allegiance to ISIS,” California Rep. Adam Schiff, the top Democrat on the House Permanent Select Committee on Intelligence, told CNN.'\n",
      " {'top democrat'}]\n",
      "1 ['liberal' 'Gay rights advocates have been trying to get approval for a .'\n",
      " {'rights advocates'}]\n",
      "2 ['liberal'\n",
      " 'And how can a state with the highest number of poor people in the nation  —   23 percent of Californians are below the accepted poverty line, according to the Census Bureau  —   ensure that its gas prices will be the highest in the nation?'\n",
      " {'poverty line'}]\n",
      "3 ['liberal'\n",
      " 'But if there’s abundant video of you demanding respect for law, it becomes a bigger problem if there’s also abundant video of you breaking laws to take financial advantage of ordinary people.'\n",
      " {'bigger problem'}]\n",
      "4 ['liberal' 'The sign reads, “Undocumented Immigrant?'\n",
      " {'undocumented immigrant'}]\n",
      "5 ['conservative'\n",
      " 'That’s probably not what the president of the United States had in mind when this week he set up a hotline for the Victims of Immigration Crime Engagement office (VOICE) meant to record and report crimes by “illegal aliens.'\n",
      " {'illegal aliens'}]\n",
      "6 ['liberal'\n",
      " 'That won’t be nearly enough to knock Guardians from the top spot.'\n",
      " {'nearly enough'}]\n",
      "7 ['liberal'\n",
      " 'By the time Will’s friends Mike, Lucas, and Dustin find her, she’s already witnessed the fatal shooting of a kindly restaurant owner who tried to get her help.'\n",
      " {'fatal shooting'}]\n",
      "8 ['liberal'\n",
      " 'More recently, Turks have blamed the United States and Western allies for huge street protests, a corruption scandal and this summer’s  failed military coup.'\n",
      " {'corruption scandal'}]\n",
      "9 ['conservative'\n",
      " '” “His vision stands against the open exchange of ideas, free movement of people, and productive engagement with the outside world that is critical to our economy  —   and that provide the foundation for innovation and growth,” the letter stated.'\n",
      " {'free movement'}]\n"
     ]
    }
   ],
   "source": [
    "sample = df2[df2.label != 'neutral'].sample(10)\n",
    "for i,t in enumerate(sample.values):\n",
    "    print(i,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19000"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = round(min(df2[df2.label == 'conservative'].shape[0], df2[df2.label == 'liberal'].shape[0]),-3)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.frame.DataFrame,\n",
       " pandas.core.frame.DataFrame,\n",
       " pandas.core.frame.DataFrame)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = df2.loc[df2.label == 'conservative'].sample(n)\n",
    "s2 = df2.loc[df2.label == 'liberal'].sample(n)\n",
    "s3 = df2.loc[df2.label == 'neutral'].sample(n)\n",
    "type(s1), type(s2), type(s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>grams</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>conservative</th>\n",
       "      <td>19000</td>\n",
       "      <td>19000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal</th>\n",
       "      <td>19000</td>\n",
       "      <td>19000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>19000</td>\n",
       "      <td>19000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               text  grams\n",
       "label                     \n",
       "conservative  19000  19000\n",
       "liberal       19000  19000\n",
       "neutral       19000  19000"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.append(s2).append(s3).groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((57000, 3), 57000)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = s1.append(s2).append(s3)\n",
    "df2.shape, n*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r'../data/filteredNews_top50grams.pickle', 'wb') as f:\n",
    "#     pickle.dump(df1, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(r'../data/filteredNews_bigrams2.pickle', 'wb') as f:\n",
    "    pickle.dump(df2, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r'../data/filteredNews_top50grams.pickle', 'rb') as f:\n",
    "#     df1 = pickle.load(f)\n",
    "with open(r'../data/filteredNews_bigrams2.pickle', 'rb') as f:\n",
    "    df2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57000, 3)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>grams</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>conservative</th>\n",
       "      <td>19000</td>\n",
       "      <td>19000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal</th>\n",
       "      <td>19000</td>\n",
       "      <td>19000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>19000</td>\n",
       "      <td>19000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               text  grams\n",
       "label                     \n",
       "conservative  19000  19000\n",
       "liberal       19000  19000\n",
       "neutral       19000  19000"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label', 'text'], dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['conservative'\n",
      " 'Today  …     and until people I know and love can feel safe again     —   BeTheChange (@honoraye)  In the wake of Trump’s victory on Tuesday,   vandalism, hate speech and violence have been reported across the country.'\n",
      " {'hate speech'}]\n",
      "1 ['conservative'\n",
      " 'It’s gotta be the other way around.”  The Netherlands’ relationship with the European Union has been another hot topic on the campaign trail.'\n",
      " {'got ta'}]\n",
      "2 ['conservative'\n",
      " 'May payrolls were revised sharply down to show them rising 11, 000 rather than the previously reported 38, 000.'\n",
      " {'previously reported'}]\n",
      "3 ['conservative'\n",
      " 'Ginsberg, Senior Political Editor, The Washington Post   Samuels, National Political Reporter, The Washington Post   Phillip, National Political Reporter The Washington Post Moderated by Dan Balz, Chief Correspondent, The Washington Post         July 25, 1:30  —   2:30 p. m. | Party Platform: Criminal Justice Policymakers and experts examine the Democrats’ party platform on policing and criminal justice reform.'\n",
      " {'senior political'}]\n",
      "4 ['liberal'\n",
      " 'SYDNEY British consortium GFG Alliance said on Wednesday it has signed a binding agreement to acquire deeply indebted Australian steel company Arrium Ltd, trumping a South Korean group backed by steel giant Posco.'\n",
      " {'south korean'}]\n",
      "5 ['liberal'\n",
      " 'Trump Derangement Syndrome: Larry Summers Worries We Might Export Natural Gas To China - Breitbart'\n",
      " {'natural gas'}]\n",
      "6 ['liberal'\n",
      " '”But the truth of the matter is I was a kid when I got married and I think that’s almost in every case a bad idea.” Loopholes In Legal Marrying Age, Advocates say child marriage endangers girls’ health, undermines their education and economic opportunities, and puts them at higher risk for domestic violence as well as divorce.'\n",
      " {'domestic violence'}]\n",
      "7 ['liberal'\n",
      " 'The economy, the health care system, the education system have all broken down.'\n",
      " {'care system'}]\n",
      "8 ['liberal'\n",
      " 'McCrory sued the federal government in May, after U. S. Attorney General Loretta Lynch said HB2 violated both the Civil Rights Act and Title IX and threatened to withhold federal funding to the state.'\n",
      " {'rights act'}]\n",
      "9 ['conservative'\n",
      " 'You gotta have heart, c. “I support politicians,” Donald J. Trump explained at last Thursday’s Republican debate in Detroit, after being challenged on his campaign checks to Democrats.'\n",
      " {'got ta'}]\n",
      "10 ['conservative'\n",
      " 'Moreover, as I explained in an August column, the Free Syrian Army has long been coopted by the Muslim Brotherhood  —   an       organization that the Obama administration (very much including the State Department under Secretary Clinton) portrays as “moderate.'\n",
      " {'muslim brotherhood'}]\n",
      "11 ['liberal'\n",
      " 'Next must come special counsel to run the Russia investigation, who could be appointed by Deputy Attorney General Rod Rosenstein.'\n",
      " {'russia investigation', 'deputy attorney'}]\n",
      "12 ['liberal'\n",
      " '” There is truth on both sides, said Lee Epstein, a law professor and political scientist at Washington University in St. Louis.'\n",
      " {'political scientist'}]\n",
      "13 ['liberal'\n",
      " 'In another study, Elie Bursztein, head of Google’s   research team, tracked whether people would pick up a USB thumb drive they found lying on the ground and stick it into their computers (which, he noted, was used as a major plot point in season one of USA Network’s Mr Robot).'\n",
      " {'season one'}]\n",
      "14 ['conservative'\n",
      " '” When Osteen launched his Sirius XM radio show in 2014, Trump was his first guest.'\n",
      " {'radio show'}]\n",
      "15 ['conservative'\n",
      " 'In September, the German Chancellor asked Zuckerberg to deal with “hate speech against migrants,” and a few months later, Facebook announces it would work with German authorities to deal with hate speech against migrants.'\n",
      " {'hate speech'}]\n",
      "16 ['conservative'\n",
      " 'Cruz says the people who have been hurt the most in the Obama economy have been the most vulnerable like   single moms, etc.'\n",
      " {'cruz says'}]\n",
      "17 ['liberal'\n",
      " 'I adjust incomes for the rise in the cost of living, using the superior price index preferred by the Federal Reserve Board  —   whose mandate is to keep inflation under control  —   and the Congressional Budget Office.'\n",
      " {'congressional budget', 'budget office'}]\n",
      "18 ['liberal'\n",
      " 'And for thousands like Cham who’ve fled the regime, the results could decide whether they can finally return home.'\n",
      " {'decide whether'}]\n",
      "19 ['conservative'\n",
      " 'In the   matchup, Clinton and Trump drop 6 points each, while Johnson lands at 11% support, his highest standing since a Fox News poll in early June found 12% backing the Libertarian candidate.'\n",
      " {'news poll'}]\n"
     ]
    }
   ],
   "source": [
    "sample = df2[df2.label != 'neutral'].sample(20)\n",
    "for i,t in enumerate(sample.values):\n",
    "    print(i,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/alex/Documents/MIDS/w266/final_project/w266_final_project\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('filtered_sentences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7255961894989014"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "with open('filtered_sentences.pickle', 'wb') as f:\n",
    "    pickle.dump(df, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open('filtered_sentences.pickle', 'rb') as f:\n",
    "    df2 = pickle.load(f)\n",
    "time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.2353599071502686"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "df.to_csv('filtered_sentences.csv')\n",
    "df3 = pd.read_csv('filtered_sentences.csv')\n",
    "time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('filtered_sentences.pickle', 'rb') as f:\n",
    "    df2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>liberal</td>\n",
       "      <td>WASHINGTON  —   Congressional Republicans have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>liberal</td>\n",
       "      <td>The incoming Trump administration could choose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>liberal</td>\n",
       "      <td>In another twist, Donald J. Trump’s administra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>liberal</td>\n",
       "      <td>“Given that this pending litigation involves t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>liberal</td>\n",
       "      <td>“Upon taking office, the Trump administration ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "0  liberal  WASHINGTON  —   Congressional Republicans have...\n",
       "1  liberal  The incoming Trump administration could choose...\n",
       "2  liberal  In another twist, Donald J. Trump’s administra...\n",
       "3  liberal  “Given that this pending litigation involves t...\n",
       "4  liberal  “Upon taking office, the Trump administration ..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
