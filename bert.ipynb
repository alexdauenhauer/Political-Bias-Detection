{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Political Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "import pickle\n",
    "from apex import amp\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's activate CUDA for GPU based operations\n",
    "device=torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the PATH variable to whereever your `week06/hw` directory is located.  \n",
    "**For the final run we would like you to have a train_size of at least 1 Million rows, and a valid size of at least 500K rows. When you first run the script, feel free to work with a reduced train and valid size for speed.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In bert we need all inputs to have the same length, we will use the first 220 characters. \n",
    "MAX_SEQUENCE_LENGTH = 220\n",
    "SEED = 1234\n",
    "# We shall run a single epoch (ie. one pass over the data)\n",
    "EPOCHS = 1\n",
    "PATH = '/root/w266_final_project' # /root/v2/week06/hw\"\n",
    "DATA_DIR = os.path.join(PATH, \"../data\")\n",
    "WORK_DIR = os.path.join(PATH, \"../workingdir\")\n",
    "\n",
    "# Validation and training sizes are here. \n",
    "train_size= 1000 #  10000\n",
    "valid_size= 200  #  5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should be the files you downloaded earlier when you ran `download.sh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['uncased_L-12_H-768_A-12',\n",
       " 'articles2.csv',\n",
       " 'conCons2.pickle',\n",
       " 'articles3.csv',\n",
       " 'ibcData.pkl',\n",
       " 'filteredConvote2.pickle',\n",
       " 'filteredIBC.pickle',\n",
       " 'conGrams2.pickle',\n",
       " 'filteredConvote.pickle',\n",
       " 'filteredIBC_rootOnly.pickle',\n",
       " 'wwm_uncased_L-24_H-1024_A-16',\n",
       " 'all-the-news.zip',\n",
       " 'libGrams2.pickle',\n",
       " 'libCons2.pickle',\n",
       " 'cased_L-12_H-768_A-12',\n",
       " 'filtered_sentences.pickle',\n",
       " 'articles1.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data and transform into tsv for bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/filteredConvote.pickle', 'rb') as f:\n",
    "    convote = pickle.load(f)\n",
    "with open('../data/filteredIBC.pickle', 'rb') as f:\n",
    "    ibc = pickle.load(f)\n",
    "df = convote.append(ibc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>conservative</td>\n",
       "      <td>madam speaker , i rise in strong support of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>conservative</td>\n",
       "      <td>let me note that i am one of several , if not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>conservative</td>\n",
       "      <td>i supported the patriot act and would have aga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>conservative</td>\n",
       "      <td>that , i do not believe , should be tolerated ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>conservative</td>\n",
       "      <td>second of all , let me note that any , any inv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          label                                               text\n",
       "0  conservative  madam speaker , i rise in strong support of th...\n",
       "1  conservative  let me note that i am one of several , if not ...\n",
       "2  conservative  i supported the patriot act and would have aga...\n",
       "3  conservative  that , i do not believe , should be tolerated ...\n",
       "4  conservative  second of all , let me note that any , any inv..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall install pytorch BERT implementation.   \n",
    "If you would like to experiment with or view any code (purely optional, and not graded :) ), you can copy the files from the repo https://github.com/huggingface/pytorch-pretrained-BERT  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from pytorch_pretrained_bert import convert_tf_checkpoint_to_pytorch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertForSequenceClassification,BertAdam\n",
    "from pytorch_pretrained_bert.modeling import BertModel\n",
    "from pytorch_pretrained_bert import BertConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall now load the model. When you run this, comment out the `capture` command to understand the archecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Translate model from tensorflow to pytorch\n",
    "BERT_MODEL_PATH = os.path.join(DATA_DIR, 'cased_L-12_H-768_A-12')\n",
    "convert_tf_checkpoint_to_pytorch.convert_tf_checkpoint_to_pytorch(\n",
    "                            os.path.join(BERT_MODEL_PATH, 'bert_model.ckpt'),\n",
    "                            os.path.join(BERT_MODEL_PATH, 'bert_config.json'), \n",
    "                            os.path.join(WORK_DIR, 'pytorch_model.bin'))\n",
    "\n",
    "shutil.copyfile(os.path.join(BERT_MODEL_PATH, 'bert_config.json'), \\\n",
    "                os.path.join(WORK_DIR, 'bert_config.json'))\n",
    "# This is the Bert configuration file\n",
    "bert_config = BertConfig(os.path.join(WORK_DIR, 'bert_config.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bert needs a special formatting of sentences, so we have a sentence start and end token, as well as separators.   \n",
    "Thanks to this [script](https://www.kaggle.com/httpwwwfszyc/bert-in-keras-taming) for a fast convertor of the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_lines(example, max_seq_length,tokenizer):\n",
    "    max_seq_length -=2\n",
    "    all_tokens = []\n",
    "    longer = 0\n",
    "    for text in tqdm_notebook(example):\n",
    "        tokens_a = tokenizer.tokenize(text)\n",
    "        if len(tokens_a)>max_seq_length:\n",
    "            tokens_a = tokens_a[:max_seq_length]\n",
    "            longer += 1\n",
    "        one_token = tokenizer.convert_tokens_to_ids([\"[CLS]\"]+tokens_a+[\"[SEP]\"])+[0] * (max_seq_length - len(tokens_a))\n",
    "        all_tokens.append(one_token)\n",
    "    print(longer)\n",
    "    return np.array(all_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the BERT tokenizer and convert the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 1200 records\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0a7bec865849ad9c8bf03de0ab7ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_PATH, cache_dir=None,do_lower_case=True)\n",
    "# train_all = pd.read_csv(os.path.join(DATA_DIR, \"train.csv\")).sample(train_size+valid_size,random_state=SEED)\n",
    "train_all = df.sample(train_size+valid_size,random_state=SEED)\n",
    "print('loaded %d records' % len(train_all))\n",
    "\n",
    "# Make sure all comment_text values are strings\n",
    "train_all['text'] = train_all['text'].astype(str) \n",
    "# print(train_all)\n",
    "\n",
    "sequences = convert_lines(train_all[\"text\"],MAX_SEQUENCE_LENGTH,tokenizer)\n",
    "# train_all=train_all.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at how the tokenising works in BERT, see below how it recongizes misspellings - words the model never saw. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>166053</th>\n",
       "      <td>Epstein argues on both sides of this issue by ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8991</th>\n",
       "      <td>if the gentleman will yield , i want us to tal...</td>\n",
       "      <td>conservative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84163</th>\n",
       "      <td>may benefit the United States as a whole</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5072</th>\n",
       "      <td>i have looked carefully at the law and i have ...</td>\n",
       "      <td>conservative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23065</th>\n",
       "      <td>this is not the original version of the bill t...</td>\n",
       "      <td>conservative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text         label\n",
       "166053  Epstein argues on both sides of this issue by ...       neutral\n",
       "8991    if the gentleman will yield , i want us to tal...  conservative\n",
       "84163            may benefit the United States as a whole       neutral\n",
       "5072    i have looked carefully at the law and i have ...  conservative\n",
       "23065   this is not the original version of the bill t...  conservative"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all[[\"text\", 'label']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets tokenize some text (I intentionally mispelled some words to check berts subword information handling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi , i am learning new things in w ##25 ##1 about deep learning the cloud and te ##h edge .'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Hi, I am learning new things in w251 about deep learning the cloud and teh edge.'\n",
    "tokens = tokenizer.tokenize(text)\n",
    "' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Added start and end token and convert to ids. This is how it is fed into BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'101 20844 117 178 1821 3776 1207 1614 1107 192 17600 1475 1164 1996 3776 1103 7180 1105 21359 1324 2652 119 102'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
    "input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "' '.join(map(str, input_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When BERT converts this sentence to a torch tensor below is shape of the stored tensors.  \n",
    "We have 12 input tensors, while the sentence tokens has length 23; where are can you see the 23 tokens in the tensors ?... **Feel free to post in slack or discuss in class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence tokens ['[CLS]', 'hi', ',', 'i', 'am', 'learning', 'new', 'things', 'in', 'w', '##25', '##1', 'about', 'deep', 'learning', 'the', 'cloud', 'and', 'te', '##h', 'edge', '.', '[SEP]']\n",
      "Number of tokens 23\n",
      "Tensor shapes : [(1, 23, 768), (1, 23, 768), (1, 23, 768), (1, 23, 768), (1, 23, 768), (1, 23, 768), (1, 23, 768), (1, 23, 768), (1, 23, 768), (1, 23, 768), (1, 23, 768), (1, 23, 768)]\n",
      "Number of torch tensors : 12\n"
     ]
    }
   ],
   "source": [
    "# put input on gpu and make prediction\n",
    "bert = BertModel.from_pretrained(WORK_DIR).cuda()\n",
    "bert_output = bert(torch.tensor([input_ids]).cuda())\n",
    "\n",
    "print('Sentence tokens {}'.format(tokens))\n",
    "print('Number of tokens {}'.format(len(tokens)))\n",
    "print('Tensor shapes : {}'.format([b.cpu().detach().numpy().shape for b in bert_output[0]]))\n",
    "print('Number of torch tensors : {}'.format(len(bert_output[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is a binary problem, we change our target to [0,1], instead of float.   \n",
    "We also split the dataset into a training and validation set, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all.loc[train_all['label'] == 'liberal', 'label'] = 0\n",
    "train_all.loc[train_all['label'] == 'neutral', 'label'] = 1\n",
    "train_all.loc[train_all['label'] == 'conservative', 'label'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data - sentences\n",
    "X = sequences[:train_size] \n",
    "# Target - the toxicity. \n",
    "y = train_all[['label']].values[:train_size]\n",
    "X_val = sequences[train_size:]                \n",
    "y_val = train_all[['label']].values[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  101   174  3491 ...     0     0     0]\n",
      " [  101  1191  1103 ...     0     0     0]\n",
      " [  101  1336  5257 ...     0     0     0]\n",
      " ...\n",
      " [  101 16821  2993 ...     0     0     0]\n",
      " [  101   182  1197 ...     0     0     0]\n",
      " [  101 22035  1174 ...     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=train_all.tail(valid_size).copy()\n",
    "train_df=train_all.head(train_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From here on in we would like you to run BERT.**   \n",
    "**Please do rely on the script available -  [Kaggle kernel](https://www.kaggle.com/yuval6967/toxic-bert-plain-vanila) from [yuval r](https://www.kaggle.com/yuval6967) - for at least the first few steps up to training and prediction.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**1)**   \n",
    "**Load the training set to a training dataset. For this you need to load the X sequences and y objects to torch tensors**   \n",
    "**You can use `torch.utils.data.TensorDataset` to input these into a train_dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data creations\n",
    "train_dataset = torch.utils.data.TensorDataset(torch.tensor(list(X),dtype=torch.float), torch.tensor(list(y),dtype=torch.float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)**  \n",
    "**Set your learning rate and batch size; and optionally random seeds if you want reproducable results**   \n",
    "**Load your pretrained BERT using `BertForSequenceClassification`**   \n",
    "**Initialise the gradients and place the model on cuda, set up your optimiser and decay parameters**\n",
    "**Initialise the model with `apex` (we imprted this as `amp`) for mixed precision training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f2cb201fdf0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_model_file = \"bert_pytorch.bin\"\n",
    "\n",
    "lr=2e-5\n",
    "batch_size = 32\n",
    "accumulation_steps=2\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(WORK_DIR,cache_dir=None,num_labels=3)\n",
    "model.zero_grad()\n",
    "model = model.to(device)\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "train = train_dataset\n",
    "\n",
    "num_train_optimization_steps = int(EPOCHS*len(train)/batch_size/accumulation_steps)\n",
    "\n",
    "optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                     lr=lr,\n",
    "                     warmup=0.05,\n",
    "                     t_total=num_train_optimization_steps)\n",
    "\n",
    "model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\",verbosity=0)\n",
    "model=model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3)**  \n",
    "**Start training your model by iterating through batches in a single epoch of the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tq = tqdm_notebook(range(EPOCHS))\n",
    "for epoch in tq:\n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "    avg_loss = 0.\n",
    "    avg_accuracy = 0.\n",
    "    lossf=None\n",
    "    tk0 = tqdm_notebook(enumerate(train_loader),total=len(train_loader),leave=False)\n",
    "    optimizer.zero_grad()   # Bug fix - thanks to @chinhuic\n",
    "    for i,(x_batch, y_batch) in tk0:\n",
    "#        optimizer.zero_grad()\n",
    "        y_pred = model(x_batch.to(device), attention_mask=(x_batch>0).to(device), labels=None)\n",
    "        loss =  F.cross_entropy(y_pred,y_batch.to(device))\n",
    "        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "            scaled_loss.backward()\n",
    "        if (i+1) % accumulation_steps == 0:             # Wait for several backward steps\n",
    "            optimizer.step()                            # Now we can do an optimizer step\n",
    "            optimizer.zero_grad()\n",
    "        if lossf:\n",
    "            lossf = 0.98*lossf+0.02*loss.item()\n",
    "        else:\n",
    "            lossf = loss.item()\n",
    "        tk0.set_postfix(loss = lossf)\n",
    "        avg_loss += loss.item() / len(train_loader)\n",
    "        avg_accuracy += torch.mean(((torch.sigmoid(y_pred[:,0])>0.5) == (y_batch[:,0]>0.5).to(device)).to(torch.float) ).item()/len(train_loader)\n",
    "    tq.set_postfix(avg_loss=avg_loss,avg_accuracy=avg_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4)**  \n",
    "**Store your trained model to disk, you will need it if you choose section 8C.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), output_model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5)**   \n",
    "**Now make a prediction for your validation set.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification(bert_config,num_labels=1)\n",
    "model.load_state_dict(torch.load(output_model_file ))\n",
    "model.to(device)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad=False\n",
    "model.eval()\n",
    "valid_preds = np.zeros((len(X_val)))\n",
    "valid = torch.utils.data.TensorDataset(torch.tensor(X_val,dtype=torch.long))\n",
    "valid_loader = torch.utils.data.DataLoader(valid, batch_size=32, shuffle=False)\n",
    "\n",
    "tk0 = tqdm_notebook(valid_loader)\n",
    "for i,(x_batch,)  in enumerate(tk0):\n",
    "    pred = model(x_batch.to(device), attention_mask=(x_batch>0).to(device), labels=None)\n",
    "    valid_preds[i*32:(i+1)*32]=pred[:,0].detach().cpu().squeeze().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6)**  \n",
    "**In the yuval's kernel he get a metric based on the metric for the jigsaw competition - it is quite complicated. Instead, we would like you to measure the `AUC`, similar to how you did in homework 04. You can compare the results to HW04**  \n",
    "*A tip, if your score is lower than homework 04 something is wrong....*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=torch.sigmoid(torch.tensor(valid_preds)).numpy()\n",
    "print('AUC score : {:.5f}'.format(roc_auc_score(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7)**  \n",
    "**Can you show/print the validation sentences predicted with the highest and lowest toxicity ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_pred = np.argsort(y_pred)\n",
    "print(\"Highest Score: {}\".format(y_pred[sorted_pred[-1]]))\n",
    "print(\"Highest: {}\".format(train_all[['comment_text']].values[sorted_pred[-1]]))\n",
    "print(\"Lowest Score: {}\".format(y_pred[sorted_pred[0]]))\n",
    "print(\"Lowest: {}\".format(train_all[['comment_text']].values[sorted_pred[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8)**  \n",
    "**Pick only one of the below items and complete it. The last two will take a good amount of time (and partial success on them is fine), so proceed with caution on your choice of items :)** \n",
    "  \n",
    "  \n",
    "**A. Can you train on two epochs ?**\n",
    "\n",
    "**B. Can you change the learning rate and improve validation score ?**\n",
    "   \n",
    "**C. Make a prediction on the test data set with your downloaded model and submit to Kaggle to see where you score on public LB - check out [Abhishek's](https://www.kaggle.com/abhishek) script - https://www.kaggle.com/abhishek/pytorch-bert-inference**  \n",
    "  \n",
    "**D. Get BERT running on the tx2 for a sample of the data.** \n",
    "  \n",
    "**E. Finally, and very challenging -- the `BertAdam` optimiser proved to be suboptimal for this task. There is a better optimiser for this dataset in this script [here](https://www.kaggle.com/cristinasierra/pretext-lstm-tuning-v3). Check out the `custom_loss` function. Can you implement it ? It means getting under the hood of the `BertForSequenceClassification` at the source repo and implementing a modified version locally .  `https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/pytorch_pretrained_bert/modeling.py`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### PART A ###\n",
    "output_model_file = \"bert_pytorch_part_a.bin\"\n",
    "EPOCHS_A = 2\n",
    "\n",
    "lr=2e-5\n",
    "batch_size = 32\n",
    "accumulation_steps=2\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "model_a = BertForSequenceClassification.from_pretrained(WORK_DIR,cache_dir=None,num_labels=1)\n",
    "model_a.zero_grad()\n",
    "model_a = model_a.to(device)\n",
    "param_optimizer = list(model_a.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "train = train_dataset\n",
    "\n",
    "num_train_optimization_steps = int(EPOCHS_A*len(train)/batch_size/accumulation_steps)\n",
    "\n",
    "optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                     lr=lr,\n",
    "                     warmup=0.05,\n",
    "                     t_total=num_train_optimization_steps)\n",
    "\n",
    "model_a, optimizer = amp.initialize(model_a, optimizer, opt_level=\"O1\",verbosity=0)\n",
    "model_a=model_a.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PART A ###\n",
    "tq = tqdm_notebook(range(EPOCHS_A))\n",
    "for epoch in tq:\n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "    avg_loss = 0.\n",
    "    avg_accuracy = 0.\n",
    "    lossf=None\n",
    "    tk0 = tqdm_notebook(enumerate(train_loader),total=len(train_loader),leave=False)\n",
    "    optimizer.zero_grad()   # Bug fix - thanks to @chinhuic\n",
    "    for i,(x_batch, y_batch) in tk0:\n",
    "#        optimizer.zero_grad()\n",
    "        y_pred = model_a(x_batch.to(device), attention_mask=(x_batch>0).to(device), labels=None)\n",
    "        loss =  F.binary_cross_entropy_with_logits(y_pred,y_batch.to(device))\n",
    "        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "            scaled_loss.backward()\n",
    "        if (i+1) % accumulation_steps == 0:             # Wait for several backward steps\n",
    "            optimizer.step()                            # Now we can do an optimizer step\n",
    "            optimizer.zero_grad()\n",
    "        if lossf:\n",
    "            lossf = 0.98*lossf+0.02*loss.item()\n",
    "        else:\n",
    "            lossf = loss.item()\n",
    "        tk0.set_postfix(loss = lossf)\n",
    "        avg_loss += loss.item() / len(train_loader)\n",
    "        avg_accuracy += torch.mean(((torch.sigmoid(y_pred[:,0])>0.5) == (y_batch[:,0]>0.5).to(device)).to(torch.float) ).item()/len(train_loader)\n",
    "    tq.set_postfix(avg_loss=avg_loss,avg_accuracy=avg_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_a.state_dict(), output_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a = BertForSequenceClassification(bert_config,num_labels=1)\n",
    "# model_a = BertForSequenceClassification.from_pretrained(output_model_file)\n",
    "model_a.load_state_dict(torch.load(output_model_file ))\n",
    "model_a.to(device)\n",
    "for param in model_a.parameters():\n",
    "    param.requires_grad=False\n",
    "model_a.eval()\n",
    "valid_preds_a = np.zeros((len(X_val)))\n",
    "valid_a = torch.utils.data.TensorDataset(torch.tensor(X_val,dtype=torch.long))\n",
    "valid_loader_a = torch.utils.data.DataLoader(valid_a, batch_size=32, shuffle=False)\n",
    "\n",
    "tk0 = tqdm_notebook(valid_loader_a)\n",
    "for i,(x_batch,)  in enumerate(tk0):\n",
    "    pred = model_a(x_batch.to(device), attention_mask=(x_batch>0).to(device), labels=None)\n",
    "    valid_preds_a[i*32:(i+1)*32]=pred[:,0].detach().cpu().squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=torch.sigmoid(torch.tensor(valid_preds_a)).numpy()\n",
    "print('AUC score : {:.5f}'.format(roc_auc_score(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We see a very small delta in the AUC score when we train on two epochs. This suggests that one epoch is enough considering everything else in our setup.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PART B ###\n",
    "output_model_file = \"bert_pytorch_part_b.bin\"\n",
    "\n",
    "lr=1e-5\n",
    "batch_size = 32\n",
    "accumulation_steps=2\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "model_b = BertForSequenceClassification.from_pretrained(WORK_DIR,cache_dir=None,num_labels=1)\n",
    "model_b.zero_grad()\n",
    "model_b = model_b.to(device)\n",
    "param_optimizer = list(model_b.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "train = train_dataset\n",
    "\n",
    "num_train_optimization_steps = int(EPOCHS*len(train)/batch_size/accumulation_steps)\n",
    "\n",
    "optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                     lr=lr,\n",
    "                     warmup=0.05,\n",
    "                     t_total=num_train_optimization_steps)\n",
    "\n",
    "model_b, optimizer = amp.initialize(model_b, optimizer, opt_level=\"O1\",verbosity=0)\n",
    "model_b=model_b.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PART B ###\n",
    "tq = tqdm_notebook(range(EPOCHS))\n",
    "for epoch in tq:\n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "    avg_loss = 0.\n",
    "    avg_accuracy = 0.\n",
    "    lossf=None\n",
    "    tk0 = tqdm_notebook(enumerate(train_loader),total=len(train_loader),leave=False)\n",
    "    optimizer.zero_grad()   # Bug fix - thanks to @chinhuic\n",
    "    for i,(x_batch, y_batch) in tk0:\n",
    "#        optimizer.zero_grad()\n",
    "        y_pred = model_b(x_batch.to(device), attention_mask=(x_batch>0).to(device), labels=None)\n",
    "        loss =  F.binary_cross_entropy_with_logits(y_pred,y_batch.to(device))\n",
    "        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "            scaled_loss.backward()\n",
    "        if (i+1) % accumulation_steps == 0:             # Wait for several backward steps\n",
    "            optimizer.step()                            # Now we can do an optimizer step\n",
    "            optimizer.zero_grad()\n",
    "        if lossf:\n",
    "            lossf = 0.98*lossf+0.02*loss.item()\n",
    "        else:\n",
    "            lossf = loss.item()\n",
    "        tk0.set_postfix(loss = lossf)\n",
    "        avg_loss += loss.item() / len(train_loader)\n",
    "        avg_accuracy += torch.mean(((torch.sigmoid(y_pred[:,0])>0.5) == (y_batch[:,0]>0.5).to(device)).to(torch.float) ).item()/len(train_loader)\n",
    "    tq.set_postfix(avg_loss=avg_loss,avg_accuracy=avg_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_b.state_dict(), output_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b = BertForSequenceClassification(bert_config,num_labels=1)\n",
    "model_b.load_state_dict(torch.load(output_model_file ))\n",
    "model_b.to(device)\n",
    "for param in model_b.parameters():\n",
    "    param.requires_grad=False\n",
    "model_b.eval()\n",
    "valid_preds = np.zeros((len(X_val)))\n",
    "valid = torch.utils.data.TensorDataset(torch.tensor(X_val,dtype=torch.long))\n",
    "valid_loader = torch.utils.data.DataLoader(valid, batch_size=32, shuffle=False)\n",
    "\n",
    "tk0 = tqdm_notebook(valid_loader)\n",
    "for i,(x_batch,)  in enumerate(tk0):\n",
    "    pred = model_b(x_batch.to(device), attention_mask=(x_batch>0).to(device), labels=None)\n",
    "    valid_preds[i*32:(i+1)*32]=pred[:,0].detach().cpu().squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=torch.sigmoid(torch.tensor(valid_preds)).numpy()\n",
    "print('AUC score : {:.5f}'.format(roc_auc_score(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We see a very small change in our AUC when we halved the learning rate. This suggests that slowing down the learning rate any further will not yield better results. We could explore increasing the learning rate to speed up our training.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
